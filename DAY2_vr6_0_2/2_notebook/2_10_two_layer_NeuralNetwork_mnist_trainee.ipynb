{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2層ニューラルネットワークでMNISTを解く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from common.activations import softmax, sigmoid\n",
    "from common.grad import numerical_gradient\n",
    "from common.loss import cross_entropy_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層ニューラルネットワーククラスに正解率(Accuracy)を求める関数を追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 2層ニューラルネットワーククラスに正解率(Accuracy)を求める関数を追加しましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒント\n",
    "y = np.array([\n",
    "            [0.1, 0.9],\n",
    "            [0.8, 0.2],\n",
    "            [0.3, 0.7]])\n",
    "t = np.array([\n",
    "            [0, 1],\n",
    "            [0, 1],\n",
    "            [1, 0]])\n",
    "\n",
    "y = np.argmax(y, axis=1)\n",
    "print(\"argmax(y)=\", y)\n",
    "\n",
    "t = np.argmax(t, axis=1)\n",
    "print(\"argmax(t)=\", t)\n",
    "\n",
    "print(np.sum(y==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet():\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        \n",
    "        # 重みの初期化\n",
    "        self.params = {}\n",
    "        init_std=0.01\n",
    "        np.random.seed(1234)\n",
    "        self.params[\"W1\"] = init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params[\"b1\"] = np.zeros(hidden_size)\n",
    "        self.params[\"W2\"] = init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params[\"b2\"] = np.zeros(output_size)\n",
    "                \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        予測関数\n",
    "        x : 入力データ\n",
    "        \"\"\"\n",
    "        W1, W2 = self.params[\"W1\"], self.params[\"W2\"]\n",
    "        b1, b2 = self.params[\"b1\"], self.params[\"b2\"]\n",
    "        \n",
    "        h1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(h1)\n",
    "        h2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(h2)\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        \"\"\"\n",
    "        損失関数\n",
    "        x : 入力データ\n",
    "        t : 正解データ\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        return loss\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"\n",
    "        勾配計算関数\n",
    "        \"\"\"\n",
    "        grads={}\n",
    "        f = self.loss\n",
    "        grads[\"W1\"] = numerical_gradient(f, x, self.params[\"W1\"], t)\n",
    "        grads[\"b1\"] = numerical_gradient(f, x, self.params[\"b1\"], t)\n",
    "        grads[\"W2\"] = numerical_gradient(f, x, self.params[\"W2\"], t)\n",
    "        grads[\"b2\"] = numerical_gradient(f, x, self.params[\"b2\"], t)\n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        \"\"\"\n",
    "        正解率を算出する関数\n",
    "        \"\"\"\n",
    "        y = self.predict(      )\n",
    "        y = np.argmax(    , axis=1)\n",
    "        t = np.argmax(    , axis=1)\n",
    "        return np.sum(   ==  ) / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNISTデータの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "train = X_train/255\n",
    "test = X_test/255\n",
    "train = train.reshape(-1, 28*28)\n",
    "test = test.reshape(-1, 28*28)\n",
    "train_labels = lb.fit_transform(y_train)\n",
    "test_labels = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ学習を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 以下のミニバッチ学習を完成させましょう。  \n",
    "* ここでは、計算が実行できることを確認できればよいので、計算に用いるデータの数は少なくしています。  \n",
    "* 計算の進行と共に損失が小さくなっていくことを確認したい場合は、以下の条件を変更する必要があります。ただし、変更すると計算時間が長くなるのでご注意ください。  \n",
    "```\n",
    "x = train[:9,:]  \n",
    "t = train_labels[:9,:]  \n",
    "epochs = 10  \n",
    "batch_size = 3  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = train[:9,:]\n",
    "t = train_labels[:9,:]\n",
    "epochs = 10\n",
    "batch_size = 3\n",
    "lr = 0.01\n",
    "\n",
    "# 繰り返し回数\n",
    "xsize = x.shape[0]\n",
    "iter_num = np.ceil(xsize / batch_size).astype(np.int) # ceilは切り上げ関数\n",
    "\n",
    "# 2層NNのオブジェクト生成\n",
    "tnet = TwoLayerNet(input_size=28*28, hidden_size=100, output_size=10)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch=%s\"%epoch)\n",
    "    \n",
    "    # シャッフル\n",
    "    idx = np.arange(xsize)\n",
    "    np.random.shuffle(idx)\n",
    "\n",
    "    for it in range(iter_num):\n",
    "        \"\"\"\n",
    "        ランダムなミニバッチを順番に取り出す\n",
    "        \"\"\"\n",
    "        mask = idx[batch_size*it : batch_size*(it+1)]\n",
    "    \n",
    "        # ミニバッチの生成\n",
    "        x_train = x[mask]\n",
    "        t_train = t[mask]\n",
    "        \n",
    "        # 勾配の計算\n",
    "        grads = tnet.gradient(     ,      )\n",
    "\n",
    "        # パラメータの更新\n",
    "        for key in tnet.params.keys():\n",
    "    #         print(key)\n",
    "            tnet.params[key] -= lr * \n",
    "\n",
    "    ## 学習経過の記録 ##\n",
    "    \n",
    "    # 訓練データにおけるloss\n",
    "    train_loss.append(tnet.loss(    ,    ))\n",
    "    \n",
    "    # テストデータにおけるloss\n",
    "    test_loss.append(tnet.loss(    ,    ))\n",
    "    \n",
    "    # 訓練データにて精度を確認\n",
    "    train_accuracy.append(tnet.accuracy(    ,    ))\n",
    "\n",
    "    # テストデータにて精度を算出\n",
    "    test_accuracy.append(tnet.accuracy(   ,     ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lossとaccuracyの変化をグラフ化\n",
    "df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "             \"test_loss\":test_loss,\n",
    "             \"train_accuracy\":train_accuracy,\n",
    "             \"test_accuracy\":test_accuracy})\n",
    "df_log.plot(style=['r-', 'r--', 'b-', 'b--'])\n",
    "plt.ylim([0,3])\n",
    "plt.ylabel(\"Accuracy or loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
