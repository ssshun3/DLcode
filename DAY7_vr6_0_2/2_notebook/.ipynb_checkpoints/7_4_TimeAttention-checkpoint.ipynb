{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeAttentionレイヤを実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from common.layers import Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 以下のWeightSum, AttentionWeight, Attention, TimeAttentionクラスを完成させましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, a):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        hs : エンコーダの中間状態\n",
    "        a : アテンション荷重\n",
    "        \"\"\"\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        # アテンション荷重の行列を3次元配列に変形する\n",
    "        ar = a.reshape(N, T, 1)#.repeat(H, axis=2)   ブロードキャストを明示的に行いたい場合はrepeatを付ける\n",
    "        # エンコーダの中間状態にアテンション荷重をかけて、それを足し合わせることによって、加重平均を求める\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "\n",
    "        self.cache = (hs, ar)\n",
    "        return c  # エンコーダの中間状態を加重平均した結果\n",
    "\n",
    "    def backward(self, dc):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \"\"\"\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "\n",
    "        return dhs, da\n",
    "\n",
    "\n",
    "class AttentionWeight:\n",
    "    \"\"\"\n",
    "    アテンション荷重を算出するクラス\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        アテンション荷重を求める\n",
    "        hs : エンコーダの全ての中間状態\n",
    "        h : デコーダのある場所の中間状態\n",
    "        \"\"\"\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        #　デコーダのある場所の中間状態を3次元配列に変形する\n",
    "        hr = h.reshape(N, 1, H)#.repeat(T, axis=1)\n",
    "        \n",
    "        # エンコーダの中間状態とデコーダの中間状態を掛けて足し合わせることで内積をとる\n",
    "        # 他の実装例として、hsとhrを結合し、重みWを掛けるという方法もある\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        \n",
    "        # ソフトマックス関数に通すことで、正規化する\n",
    "        a = self.softmax.forward(s) # アテンション重みベクトルを並べた行列 (N * T)\n",
    "\n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "\n",
    "    def backward(self, da):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \"\"\"\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "\n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "\n",
    "        return dhs, dh\n",
    "\n",
    "\n",
    "class Attention:\n",
    "    \"\"\"\n",
    "    アテンション\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        \n",
    "        # レイヤの定義\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "\n",
    "    def forward(self, hs, h):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        hs : エンコーダの中間状態\n",
    "        h : デコーダの中間状態\n",
    "        \"\"\"\n",
    "        # アテンション荷重を求める\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        \n",
    "        # エンコーダの中間状態にアテンション荷重をかける\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        \n",
    "        return out # エンコーダの中間状態を加重平均した結果\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        \"\"\"\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh\n",
    "\n",
    "\n",
    "class TimeAttention:\n",
    "    \"\"\"\n",
    "    アテンションレイヤを時間方向にまとめるレイヤ\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        \"\"\"\n",
    "        順伝播\n",
    "        hs_enc : エンコーダの中間状態\n",
    "        hs_dec : デンコーダの中間状態\n",
    "        \"\"\"\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "\n",
    "        for t in range(T):\n",
    "            \"\"\"\n",
    "            出力単語数分を繰り返す\n",
    "            \"\"\"\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:,t,:]) \n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        逆伝播\n",
    "        dout : 勾配\n",
    "        \"\"\"\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "\n",
    "        for t in range(T):\n",
    "            \"\"\"\n",
    "            出力単語数分を繰り返す\n",
    "            \"\"\"\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:,t,:] = dh\n",
    "\n",
    "        return dhs_enc, dhs_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs_enc= [[[-1.02082814  0.55732175  0.22309253 -0.27049653]\n",
      "  [ 1.08273328  0.37609399 -2.62666916  2.31467079]\n",
      "  [-0.49846795  0.69727866  0.60285361  0.9012636 ]\n",
      "  [ 1.64457397 -0.84951114  0.7382962   2.16226523]\n",
      "  [-0.27046016 -0.99635624 -0.31343818 -0.10097855]]\n",
      "\n",
      " [[ 0.08873106 -1.87342375 -2.10518475 -1.12369785]\n",
      "  [ 1.88304891 -1.56798295 -0.41669772 -0.47413281]\n",
      "  [-0.27787888 -0.38984243 -0.27826104  0.77916954]\n",
      "  [-1.8527932  -0.22046015  0.35280648 -2.09924956]\n",
      "  [-2.31658839  2.00762315 -1.41188379 -0.59375061]]\n",
      "\n",
      " [[-0.53692297 -0.6014518   0.47550973 -0.97483527]\n",
      "  [-0.04411031  0.66553113  1.47607725  0.74410961]\n",
      "  [-1.09388844  1.86195703 -0.25840725 -1.81813154]\n",
      "  [ 1.10489318  0.66724034  0.55600656  2.75490493]\n",
      "  [ 0.9024805  -1.3117066   1.16503191 -0.95704286]]]\n",
      "\n",
      "hs_dec= [[[ 0.39436226  0.9989428   1.49135418  0.43299438]\n",
      "  [-0.88883041  0.02623611 -0.4730215   0.32916778]\n",
      "  [-0.15123933  2.3083466   1.39889384 -2.15295063]\n",
      "  [ 0.66861353 -0.50004443  1.07123667  0.96612306]\n",
      "  [-0.0612255   1.63252391  0.58399135  1.50477232]]\n",
      "\n",
      " [[ 0.1719852  -1.45124683 -0.08692239 -0.27198269]\n",
      "  [ 0.14556236 -1.0860032   0.94032047 -1.06638686]\n",
      "  [-0.91964343 -0.66641716 -0.66473864  0.22835553]\n",
      "  [ 0.63592211 -0.28048094 -0.2848638  -0.14004183]\n",
      "  [ 0.96280229  0.58093591  0.02551515  2.1308779 ]]\n",
      "\n",
      " [[-1.02359855 -0.86920441 -0.66540747 -2.36432162]\n",
      "  [-1.40055296 -1.93756299 -0.8397937   0.58186624]\n",
      "  [ 0.24064961 -0.87080453 -0.76262483  1.62558317]\n",
      "  [ 0.17538667  0.6843873  -1.16254326  0.6856132 ]\n",
      "  [-0.46102627  0.92024751  2.49258512 -0.73153646]]]\n",
      "\n",
      "out= [[[ 0.42352626 -0.03616212  0.58344311  1.34264586]\n",
      "  [ 0.04206269  0.20446142 -0.76170318  0.97871498]\n",
      "  [-0.93803482  0.56695061  0.27540233 -0.09605878]\n",
      "  [ 1.54983834 -0.79003447  0.68421206  2.09642049]\n",
      "  [ 0.41435885  0.25042154 -0.34443248  1.53508099]]\n",
      "\n",
      " [[ 0.64432839 -1.64813539 -1.34372809 -0.86746695]\n",
      "  [-0.32895633 -0.89486692 -0.26393859 -1.3714987 ]\n",
      "  [-0.75048453 -0.54580488 -1.32478851 -0.90881949]\n",
      "  [ 0.91232012 -1.46402571 -0.9568183  -0.64881373]\n",
      "  [ 0.13525603 -0.59631219 -0.34637276  0.46816523]]\n",
      "\n",
      " [[-0.80751451  0.98571309  0.03614737 -1.5326269 ]\n",
      "  [-0.14915252 -0.60657683  0.64684672 -0.74105718]\n",
      "  [ 1.07875871  0.64579715  0.57302298  2.67855975]\n",
      "  [ 0.70897428  0.78687911  0.49977942  1.92100854]\n",
      "  [-0.23299705  0.68255065  0.94621395 -0.14889981]]]\n",
      "\n",
      "dhs_enc= [[[-0.73335619  0.29982436  1.03613625  0.17480351]\n",
      "  [ 0.16896138 -4.29106782  0.57166575 -3.60024125]\n",
      "  [-2.19797586  3.35114432  2.7928761   3.91575673]\n",
      "  [-2.06018908 -0.60215299 -0.708991    1.1932489 ]\n",
      "  [-0.56362535 -0.2140772   0.04392311  0.21887297]]\n",
      "\n",
      " [[ 0.39758593  1.52010657  1.08696842  0.90279186]\n",
      "  [ 1.66653244  0.42543796  1.20322318  0.09602659]\n",
      "  [-0.35045461 -1.03670645  0.12528968 -0.76204794]\n",
      "  [ 0.79942367  0.66196937 -0.22221732  0.6021536 ]\n",
      "  [-0.07424283  0.00809924 -0.04677991  0.20911391]]\n",
      "\n",
      " [[ 1.9142456   0.92322236  1.93734882  1.26007286]\n",
      "  [-1.16788751  0.79289817  3.67032191  0.23053336]\n",
      "  [-0.12365606 -0.7233139  -1.17735154 -0.94939404]\n",
      "  [ 2.24378405  1.15661041 -1.52857132  1.09125548]\n",
      "  [-0.32879248 -1.18726109 -0.40222549  0.97984994]]]\n",
      "\n",
      "dhs_dec= [[[-1.97011307e+00  1.37950855e+00 -3.11063203e-01 -1.26831761e+00]\n",
      "  [-1.77241204e+00 -4.97130273e-01  3.41395705e+00 -2.38360564e+00]\n",
      "  [-2.90502021e-02 -5.78450137e-03 -1.95823940e-02 -6.30600233e-02]\n",
      "  [ 9.17548518e-02 -4.76468941e-02  8.98477207e-02  7.32550187e-02]\n",
      "  [-3.39945879e+00  5.06891685e-01  7.04319424e+00 -3.28141609e+00]]\n",
      "\n",
      " [[-1.30408531e+00  1.01539385e-01 -6.49798206e-01 -3.55451678e-01]\n",
      "  [ 3.23215049e+00 -1.19390597e+00 -6.07991576e-01  1.29114706e+00]\n",
      "  [-5.27635322e-01  1.54184299e+00  6.55830496e-01  9.50284958e-01]\n",
      "  [ 1.91242430e+00  5.35068227e-01  1.93105583e+00  1.14585384e+00]\n",
      "  [ 6.91288649e-01 -4.52862394e-01 -1.08106231e-02 -3.11098655e-01]]\n",
      "\n",
      " [[-5.88651771e-01  1.83170448e+00 -6.10495582e-01 -5.95366237e-01]\n",
      "  [ 7.51771856e-01 -5.06326054e-01  3.96673059e-01  8.16747793e-02]\n",
      "  [-5.42647443e-03 -2.79485101e-02  1.10313413e-02 -5.69248607e-02]\n",
      "  [ 1.97513015e+00 -6.27200147e-01  3.86681022e-01  4.19138085e+00]\n",
      "  [ 8.07425899e-01 -5.09951345e-01  1.68523755e+00  2.89284964e+00]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 中間層ノード数\n",
    "H = 4\n",
    "# データ数\n",
    "N = 3\n",
    "# 単語数\n",
    "T = 5\n",
    "\n",
    "\n",
    "# モデル構築\n",
    "ta = TimeAttention()\n",
    "\n",
    "hs_enc = np.random.randn(N*T*H).reshape(N, T, H)\n",
    "hs_dec =  np.random.randn(N*T*H).reshape(N, T, H)\n",
    "print(\"hs_enc=\", hs_enc)\n",
    "print()\n",
    "print(\"hs_dec=\", hs_dec)\n",
    "print()\n",
    "\n",
    "# 順伝播計算\n",
    "out = ta.forward(hs_enc, hs_dec)\n",
    "print(\"out=\", out)\n",
    "print()\n",
    "\n",
    "# 逆伝播計算\n",
    "dout = np.random.randn(N*T*H).reshape(N, T, H)\n",
    "dhs_enc, dhs_dec = ta.backward(dout)\n",
    "print(\"dhs_enc=\", dhs_enc)\n",
    "print()\n",
    "print(\"dhs_dec=\", dhs_dec)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
