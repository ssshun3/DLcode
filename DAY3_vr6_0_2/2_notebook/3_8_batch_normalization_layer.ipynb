{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バッチ正規化(batch normalization)レイヤ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## バッチ正規化(batch normalization)レイヤの計算手順\n",
    "ここでの説明は、バッチ正規化レイヤの入力層側に設置されている層の出力値のうちの1ノード分を対象にする。  \n",
    "\n",
    "### [計算手順(学習時の順伝播計算)] \n",
    "#### (1) 計算の対象をxとする  \n",
    "$~~~$入力 :  ${\\bf x} = \\{x_1,x_2, \\dots , x_n\\}$  \n",
    "$~~~$n : データ数=バッチサイズ  \n",
    "  \n",
    "  \n",
    "#### (2) 入力の平均値を求める    \n",
    "$~~~$$\\displaystyle \\mu = \\frac{1}{n}\\sum_{i=1}^{n}x_i$\n",
    "  \n",
    "  \n",
    "#### (3) 入力の分散を求める  \n",
    "$~~~$$\\displaystyle \\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\mu)^2$\n",
    "  \n",
    "  \n",
    "#### (4) 入力を標準化する  \n",
    "$~~~$各入力値について以下の処理を行う。numpyで計算する場合はベクトルとスカラーの演算が可能。  \n",
    "$~~~$$\\displaystyle \\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2+\\epsilon}} $   \n",
    "$~~~$$\\epsilon$ : $1e-8$ (深層学習, Goodfellow, p.229)\n",
    "      \n",
    "      \n",
    "#### (5) スケールし、平行移動させる  \n",
    "$~~~$各入力値について以下の処理を行う。numpyで計算する場合はベクトルとスカラーの演算が可能。  \n",
    "$~~~$$\\displaystyle y_i = \\gamma \\hat{x}_i + \\beta $  \n",
    "$~~~$$y_i$が返り値になる。  \n",
    "$~~~$$\\gamma$と$\\beta$は、標準化された$x$の分布を最適な分布に変換するための係数であり、学習の過程で最適化されていくパラメータ。1つのミニバッチ内で計算される平均$\\mu$と分散$\\sigma^2$とは値が異なる。\n",
    "\n",
    "\n",
    "### [計算手順(予測時の順伝播計算)] \n",
    "基本的には、学習時の順伝播計算と同じだが、$\\mu$と$\\sigma^2$は、学習時に求めた移動平均値を使う\n",
    "$~~~$  \n",
    "$~~~$  \n",
    "\n",
    "  \n",
    "### [計算手順(学習時の逆伝播計算)] \n",
    "スライドの計算グラフを参照\n",
    "$~~~$  \n",
    "$~~~$  \n",
    "  \n",
    "  \n",
    "[参考]\n",
    "* 原著論文\n",
    "    * https://arxiv.org/pdf/1502.03167.pdf\n",
    "* ブログ\n",
    "    * https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 以下のバッチ正規化(batch normalization)レイヤクラスを完成させましょう.\n",
    "* 入力xは、バッチ正規化レイヤの入力層側に設置されている層の出力値. n*d行列になっていることに注意.  \n",
    "\n",
    "  入力 :  ${\\bf x}=\\quad\n",
    "    \\begin{pmatrix} \n",
    "    x_{11} & x_{12} & \\dots & x_{1d}\\\\\n",
    "    x_{21} & x_{22} & \\dots & x_{2d}\\\\\n",
    "   \\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "    x_{n1} & x_{n2} & \\dots & x_{nd}\\\\\n",
    "    \\end{pmatrix}\n",
    "    \\quad$\n",
    "\n",
    "    * ${\\bf x}$ は、n*d行列\n",
    "    * n : バッチサイズ  \n",
    "    * d : 入力層側の層のノード数    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [[1 2 3]\n",
      " [2 3 2]\n",
      " [3 1 4]\n",
      " [4 1 2]]\n",
      "mu= [2.5  1.75 2.75]\n",
      "var= [1.25   0.6875 0.6875]\n"
     ]
    }
   ],
   "source": [
    "# ヒント\n",
    "x = np.array([[1,2,3],[2,3,2],[3,1,4],[4,1,2]]) # N×D行列\n",
    "print(\"x=\",x)\n",
    "mu = np.mean(x, axis=0) # 要素数D個のベクトル\n",
    "print(\"mu=\", mu)\n",
    "var = np.mean((x-mu)**2, axis=0)  # 要素数D個のベクトル\n",
    "print(\"var=\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization:\n",
    "    def __init__(self, gamma, beta, rho=0.9, moving_mean=None, moving_var=None):\n",
    "        self.gamma = gamma # スケールさせるためのパラメータ, 学習によって更新させる.\n",
    "        self.beta = beta # シフトさせるためのパラメータ, 学習によって更新させる\n",
    "        self.rho = rho # 移動平均を算出する際に使用する係数\n",
    "\n",
    "        # 予測時に使用する平均と分散\n",
    "        self.moving_mean = moving_mean   # muの移動平均\n",
    "        self.moving_var = moving_var     # varの移動平均\n",
    "        \n",
    "        # 計算中に算出される値を保持しておく変数群\n",
    "        self.batch_size = None\n",
    "        self.x_mu = None\n",
    "        self.x_std = None        \n",
    "        self.std = None\n",
    "        self.dgamma = None\n",
    "        self.dbeta = None\n",
    "\n",
    "    def forward(self, x, train_flg=True):\n",
    "        \"\"\"\n",
    "        順伝播計算\n",
    "        x :  CNNの場合は4次元、全結合層の場合は2次元  \n",
    "        \"\"\"\n",
    "        if x.ndim == 4:\n",
    "            \"\"\"\n",
    "            画像形式の場合\n",
    "            \"\"\"\n",
    "            N, C, H, W = x.shape\n",
    "            x = x.transpose(0, 2, 3, 1) # NHWCに入れ替え\n",
    "            x = x.reshape(N*H*W, C) # (N*H*W,C)の2次元配列に変換\n",
    "            out = self.__forward(x, train_flg)\n",
    "            out = out.reshape(N, H, W, C)# 4次元配列に変換\n",
    "            out = out.transpose(0, 3, 1, 2) # 軸をNCHWに入れ替え\n",
    "        elif x.ndim == 2:\n",
    "            \"\"\"\n",
    "            画像形式以外の場合\n",
    "            \"\"\"\n",
    "            out = self.__forward(x, train_flg)           \n",
    "            \n",
    "        return out\n",
    "            \n",
    "    def __forward(self, x, train_flg, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        x : 入力. N×Dの行列. Nはバッチサイズ. Dは手前の層のノード数\n",
    "        \"\"\"\n",
    "        if (self.moving_mean is None) or (self.moving_var is None):\n",
    "            N, D = x.shape\n",
    "            self.moving_mean = np.zeros(D)\n",
    "            self.moving_var = np.zeros(D)\n",
    "                        \n",
    "        if train_flg:\n",
    "            \"\"\"\n",
    "            学習時\n",
    "            \"\"\"\n",
    "            # 入力xについて、Nの方向に平均値を算出. \n",
    "            mu = np.mean(x, axis=0) # 要素数D個のベクトル\n",
    "            mu = np.broadcast_to(mu, (N, D)) # Nの方向にブロードキャスト\n",
    "            print(\"mu.shape=\", mu.shape)\n",
    "            \n",
    "            # 入力xから平均値を引く\n",
    "            x_mu = x - mu   # N×D行列\n",
    "            print(\"x_mu.shape=\", x_mu.shape)\n",
    "            \n",
    "            # 入力xの分散を求める\n",
    "            var = np.mean(x_mu**2, axis=0)  # 要素数D個のベクトル\n",
    "            print(\"var.shape=\", var.shape)\n",
    "            \n",
    "            # 入力xの標準偏差を求める(epsilonを足してから標準偏差を求める)\n",
    "            std = np.sqrt(var + epsilon)  # 要素数D個のベクトル\n",
    "            print(\"std.shape=\", std.shape)\n",
    "            \n",
    "            # 標準偏差の逆数を求める\n",
    "            std_inv = 1 / std\n",
    "            std_inv = np.broadcast_to(std_inv, (N, D)) # Nの方向にブロードキャスト\n",
    "            print(\"std_inv.shape=\", std_inv.shape)\n",
    "            \n",
    "            # 標準化\n",
    "            x_std = x_mu * std_inv  #N*D行列\n",
    "            print(\"x_std.shape=\", x_std.shape)\n",
    "                  \n",
    "            # 値を保持しておく\n",
    "            self.batch_size = x.shape[0]\n",
    "            self.x_mu = x_mu\n",
    "            self.x_std = x_std\n",
    "            self.std = std\n",
    "            self.moving_mean = self.rho * self.moving_mean + (1-self.rho) * mu\n",
    "            self.moving_var = self.rho * self.moving_var + (1-self.rho) * var            \n",
    "        else:\n",
    "            \"\"\"\n",
    "            予測時\n",
    "            \"\"\"\n",
    "            x_mu = x - self.moving_mean # N*D行列\n",
    "            x_std = x_mu / np.sqrt(self.moving_var + epsilon) # N*D行列\n",
    "            \n",
    "        # gammaでスケールし、betaでシフトさせる\n",
    "        out = self.gamma * x_std + self.beta # N*D行列\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        逆伝播計算\n",
    "        dout : CNNの場合は4次元、全結合層の場合は2次元  \n",
    "        \"\"\"\n",
    "        if dout.ndim == 4:\n",
    "            \"\"\"\n",
    "            画像形式の場合\n",
    "            \"\"\"            \n",
    "            N, C, H, W = dout.shape\n",
    "            dout = dout.transpose(0, 2, 3, 1) # NHWCに入れ替え\n",
    "            dout = dout.reshape(N*H*W, C) # (N*H*W,C)の2次元配列に変換\n",
    "            dx = self.__backward(dout)\n",
    "            dx = dx.reshape(N, H, W, C)# 4次元配列に変換\n",
    "            dx = dx.transpose(0, 3, 1, 2) # 軸をNCHWに入れ替え\n",
    "        elif dout.ndim == 2:\n",
    "            \"\"\"\n",
    "            画像形式以外の場合\n",
    "            \"\"\"\n",
    "            dx = self.__backward(dout)\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def __backward(self, dout):\n",
    "        \"\"\"\n",
    "        ここを完成させるには、計算グラフを理解する必要があり、実装にかなり時間がかかる.\n",
    "        \"\"\"\n",
    "        N, D = self.x_mu.shape\n",
    "        \n",
    "        # betaの勾配\n",
    "        dbeta = np.sum(dout, axis=0)\n",
    "        \n",
    "        # gammaの勾配(Nの方向に合計)\n",
    "        dgamma = np.sum(self.x_std * dout, axis=0)\n",
    "        \n",
    "        # Xstdの勾配\n",
    "        a1 = self.gamma * dout\n",
    "        print(\"a1.shape=\", a1.shape)\n",
    "        \n",
    "        # Xmuの勾配(1つ目)\n",
    "        a2 = a1 / self.std\n",
    "        print(\"a2.shape=\", a2.shape)\n",
    "        \n",
    "        # 標準偏差の逆数の勾配\n",
    "        a3 = a1 * self.x_mu\n",
    "        print(\"a3.shape=\", a3.shape)\n",
    "        a3 = np.sum(a3, axis=0) # Nの方向に合計\n",
    "        \n",
    "        # 標準偏差の勾配\n",
    "        a4 = -(a3) / (self.std * self.std)\n",
    "        print(\"a4.shape=\", a4.shape)\n",
    "        \n",
    "        # 分散の勾配\n",
    "        a5 = 0.5 * a4 / self.std\n",
    "        print(\"a5.shape=\", a5.shape)\n",
    "        \n",
    "        # Xmuの2乗の勾配\n",
    "        a6 = a5 / self.batch_size\n",
    "        a6 = np.broadcast_to(a6, (N, D)) # Nの方向にブロードキャスト\n",
    "        print(\"a6=\",a6)\n",
    "        print(\"a6.shape=\", a6.shape)\n",
    "        \n",
    "        # Xmuの勾配(2つ目)\n",
    "        a7 = 2.0  * self.x_mu * a6\n",
    "        print(\"a7.shape=\", a7.shape)\n",
    "        \n",
    "        # muの勾配\n",
    "        a8 = -(a2+a7)\n",
    "        print(\"a8.shape=\", a8.shape)\n",
    "        a8 = np.sum(a8, axis=0) # Nの方向に合計\n",
    "\n",
    "        # Xの勾配\n",
    "        a9 = a8 / self.batch_size\n",
    "        a9 = np.broadcast_to(a9, (N, D)) # Nの方向にブロードキャスト\n",
    "        dx = a2 + a7 + a9\n",
    "        print(\"a9.shape=\", a9.shape)\n",
    "        \n",
    "        self.dgamma = dgamma\n",
    "        self.dbeta = dbeta\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力x=\n",
      "[[1 2 3]\n",
      " [2 3 2]\n",
      " [3 4 4]\n",
      " [4 1 2]]\n",
      "\n",
      "学習時の順伝播計算\n",
      "mu.shape= (4, 3)\n",
      "x_mu.shape= (4, 3)\n",
      "var.shape= (3,)\n",
      "std.shape= (3,)\n",
      "std_inv.shape= (4, 3)\n",
      "x_std.shape= (4, 3)\n",
      "[[-1.34164078 -0.44721359  0.30151134]\n",
      " [-0.44721359  0.44721359 -0.90453403]\n",
      " [ 0.44721359  1.34164078  1.50755671]\n",
      " [ 1.34164078 -1.34164078 -0.90453403]]\n",
      "\n",
      "予測時の順伝播計算\n",
      "[[ 2.12132026  4.94974727 10.39274147]\n",
      " [ 4.94974727  7.77817428  6.57889139]\n",
      " [ 7.77817428 10.60660129 14.20659155]\n",
      " [10.60660129  2.12132026  6.57889139]]\n",
      "\n",
      "勾配\n",
      "[[0.1 0.2 0.3]\n",
      " [0.2 0.3 0.2]\n",
      " [0.3 0.4 0.4]\n",
      " [0.4 0.1 0.2]]\n",
      "\n",
      "学習時の逆伝播計算\n",
      "a1.shape= (4, 3)\n",
      "a2.shape= (4, 3)\n",
      "a3.shape= (4, 3)\n",
      "a4.shape= (3,)\n",
      "a5.shape= (3,)\n",
      "a6= [[-0.04472136 -0.04472136 -0.06030227]\n",
      " [-0.04472136 -0.04472136 -0.06030227]\n",
      " [-0.04472136 -0.04472136 -0.06030227]\n",
      " [-0.04472136 -0.04472136 -0.06030227]]\n",
      "a6.shape= (4, 3)\n",
      "a7.shape= (4, 3)\n",
      "a8.shape= (4, 3)\n",
      "a9.shape= (4, 3)\n",
      "[[-1.07331255e-09 -3.57770841e-10  4.38561909e-10]\n",
      " [-3.57770841e-10  3.57770841e-10 -1.31568584e-09]\n",
      " [ 3.57770841e-10  1.07331258e-09  2.19280977e-09]\n",
      " [ 1.07331258e-09 -1.07331255e-09 -1.31568584e-09]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 入力が2次元の場合\n",
    "hidden_size = 3\n",
    "gamma = np.ones(hidden_size)\n",
    "beta = np.zeros(hidden_size)\n",
    "bn =BatchNormalization(gamma, beta)\n",
    "        \n",
    "x = np.array([[1,2,3],[2,3,2],[3,4,4],[4,1,2]]) # n*d行列\n",
    "print(\"入力x=\")\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "print(\"学習時の順伝播計算\")\n",
    "print(bn.forward(x, train_flg=True))\n",
    "print()\n",
    "print(\"予測時の順伝播計算\")\n",
    "print(bn.forward(x, train_flg=False))\n",
    "print()\n",
    "\n",
    "print(\"勾配\")\n",
    "dout = np.array([[0.1,0.2,0.3],[0.2,0.3,0.2],[0.3,0.4,0.4],[0.4,0.1,0.2]]) \n",
    "print(dout)\n",
    "print()\n",
    "print(\"学習時の逆伝播計算\")\n",
    "print(bn.backward(dout))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力x=\n",
      "[[[[  0   1   2]\n",
      "   [  3   4   5]\n",
      "   [  6   7   8]]\n",
      "\n",
      "  [[  9  10  11]\n",
      "   [ 12  13  14]\n",
      "   [ 15  16  17]]\n",
      "\n",
      "  [[ 18  19  20]\n",
      "   [ 21  22  23]\n",
      "   [ 24  25  26]]\n",
      "\n",
      "  [[ 27  28  29]\n",
      "   [ 30  31  32]\n",
      "   [ 33  34  35]]\n",
      "\n",
      "  [[ 36  37  38]\n",
      "   [ 39  40  41]\n",
      "   [ 42  43  44]]\n",
      "\n",
      "  [[ 45  46  47]\n",
      "   [ 48  49  50]\n",
      "   [ 51  52  53]]]\n",
      "\n",
      "\n",
      " [[[ 54  55  56]\n",
      "   [ 57  58  59]\n",
      "   [ 60  61  62]]\n",
      "\n",
      "  [[ 63  64  65]\n",
      "   [ 66  67  68]\n",
      "   [ 69  70  71]]\n",
      "\n",
      "  [[ 72  73  74]\n",
      "   [ 75  76  77]\n",
      "   [ 78  79  80]]\n",
      "\n",
      "  [[ 81  82  83]\n",
      "   [ 84  85  86]\n",
      "   [ 87  88  89]]\n",
      "\n",
      "  [[ 90  91  92]\n",
      "   [ 93  94  95]\n",
      "   [ 96  97  98]]\n",
      "\n",
      "  [[ 99 100 101]\n",
      "   [102 103 104]\n",
      "   [105 106 107]]]]\n",
      "\n",
      "学習時の順伝播計算\n",
      "mu.shape= (18, 6)\n",
      "x_mu.shape= (18, 6)\n",
      "var.shape= (6,)\n",
      "std.shape= (6,)\n",
      "std_inv.shape= (18, 6)\n",
      "x_std.shape= (18, 6)\n",
      "[[[[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]\n",
      "\n",
      "  [[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]\n",
      "\n",
      "  [[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]\n",
      "\n",
      "  [[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]\n",
      "\n",
      "  [[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]\n",
      "\n",
      "  [[-1.14293401 -1.10606517 -1.06919633]\n",
      "   [-1.03232749 -0.99545865 -0.95858981]\n",
      "   [-0.92172097 -0.88485213 -0.84798329]]]\n",
      "\n",
      "\n",
      " [[[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]\n",
      "\n",
      "  [[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]\n",
      "\n",
      "  [[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]\n",
      "\n",
      "  [[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]\n",
      "\n",
      "  [[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]\n",
      "\n",
      "  [[ 0.84798329  0.88485213  0.92172097]\n",
      "   [ 0.95858981  0.99545865  1.03232749]\n",
      "   [ 1.06919633  1.10606517  1.14293401]]]]\n",
      "\n",
      "予測時の順伝播計算\n",
      "[[[[-0.36142747 -0.24483796 -0.12824846]\n",
      "   [-0.01165895  0.10493056  0.22152006]\n",
      "   [ 0.33810957  0.45469907  0.57128858]]\n",
      "\n",
      "  [[ 0.58294753  0.69953703  0.81612654]\n",
      "   [ 0.93271604  1.04930555  1.16589506]\n",
      "   [ 1.28248456  1.39907407  1.51566357]]\n",
      "\n",
      "  [[ 1.52732252  1.64391203  1.76050153]\n",
      "   [ 1.87709104  1.99368055  2.11027005]\n",
      "   [ 2.22685956  2.34344906  2.46003857]]\n",
      "\n",
      "  [[ 2.47169752  2.58828702  2.70487653]\n",
      "   [ 2.82146604  2.93805554  3.05464505]\n",
      "   [ 3.17123455  3.28782406  3.40441356]]\n",
      "\n",
      "  [[ 3.41607251  3.53266202  3.64925153]\n",
      "   [ 3.76584103  3.88243054  3.99902004]\n",
      "   [ 4.11560955  4.23219905  4.34878856]]\n",
      "\n",
      "  [[ 4.36044751  4.47703702  4.59362652]\n",
      "   [ 4.71021603  4.82680553  4.94339504]\n",
      "   [ 5.05998454  5.17657405  5.29316356]]]\n",
      "\n",
      "\n",
      " [[[ 5.93440584  6.05099534  6.16758485]\n",
      "   [ 6.28417435  6.40076386  6.51735336]\n",
      "   [ 6.63394287  6.75053238  6.86712188]]\n",
      "\n",
      "  [[ 6.87878083  6.99537034  7.11195984]\n",
      "   [ 7.22854935  7.34513885  7.46172836]\n",
      "   [ 7.57831787  7.69490737  7.81149688]]\n",
      "\n",
      "  [[ 7.82315583  7.93974533  8.05633484]\n",
      "   [ 8.17292434  8.28951385  8.40610336]\n",
      "   [ 8.52269286  8.63928237  8.75587187]]\n",
      "\n",
      "  [[ 8.76753082  8.88412033  9.00070983]\n",
      "   [ 9.11729934  9.23388885  9.35047835]\n",
      "   [ 9.46706786  9.58365736  9.70024687]]\n",
      "\n",
      "  [[ 9.71190582  9.82849532  9.94508483]\n",
      "   [10.06167434 10.17826384 10.29485335]\n",
      "   [10.41144285 10.52803236 10.64462186]]\n",
      "\n",
      "  [[10.65628081 10.77287032 10.88945983]\n",
      "   [11.00604933 11.12263884 11.23922834]\n",
      "   [11.35581785 11.47240735 11.58899686]]]]\n",
      "\n",
      "勾配\n",
      "[[[[ 0.   0.1  0.2]\n",
      "   [ 0.3  0.4  0.5]\n",
      "   [ 0.6  0.7  0.8]]\n",
      "\n",
      "  [[ 0.9  1.   1.1]\n",
      "   [ 1.2  1.3  1.4]\n",
      "   [ 1.5  1.6  1.7]]\n",
      "\n",
      "  [[ 1.8  1.9  2. ]\n",
      "   [ 2.1  2.2  2.3]\n",
      "   [ 2.4  2.5  2.6]]\n",
      "\n",
      "  [[ 2.7  2.8  2.9]\n",
      "   [ 3.   3.1  3.2]\n",
      "   [ 3.3  3.4  3.5]]\n",
      "\n",
      "  [[ 3.6  3.7  3.8]\n",
      "   [ 3.9  4.   4.1]\n",
      "   [ 4.2  4.3  4.4]]\n",
      "\n",
      "  [[ 4.5  4.6  4.7]\n",
      "   [ 4.8  4.9  5. ]\n",
      "   [ 5.1  5.2  5.3]]]\n",
      "\n",
      "\n",
      " [[[ 5.4  5.5  5.6]\n",
      "   [ 5.7  5.8  5.9]\n",
      "   [ 6.   6.1  6.2]]\n",
      "\n",
      "  [[ 6.3  6.4  6.5]\n",
      "   [ 6.6  6.7  6.8]\n",
      "   [ 6.9  7.   7.1]]\n",
      "\n",
      "  [[ 7.2  7.3  7.4]\n",
      "   [ 7.5  7.6  7.7]\n",
      "   [ 7.8  7.9  8. ]]\n",
      "\n",
      "  [[ 8.1  8.2  8.3]\n",
      "   [ 8.4  8.5  8.6]\n",
      "   [ 8.7  8.8  8.9]]\n",
      "\n",
      "  [[ 9.   9.1  9.2]\n",
      "   [ 9.3  9.4  9.5]\n",
      "   [ 9.6  9.7  9.8]]\n",
      "\n",
      "  [[ 9.9 10.  10.1]\n",
      "   [10.2 10.3 10.4]\n",
      "   [10.5 10.6 10.7]]]]\n",
      "\n",
      "学習時の逆伝播計算\n",
      "a1.shape= (18, 6)\n",
      "a2.shape= (18, 6)\n",
      "a3.shape= (18, 6)\n",
      "a4.shape= (6,)\n",
      "a5.shape= (6,)\n",
      "a6= [[-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]\n",
      " [-0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344 -0.00184344]]\n",
      "a6.shape= (18, 6)\n",
      "a7.shape= (18, 6)\n",
      "a8.shape= (18, 6)\n",
      "a9.shape= (18, 6)\n",
      "[[[[-1.55359059e-12 -1.50347790e-12 -1.45336521e-12]\n",
      "   [-1.40325251e-12 -1.35312594e-12 -1.30301325e-12]\n",
      "   [-1.25291444e-12 -1.20278787e-12 -1.15266130e-12]]\n",
      "\n",
      "  [[-1.55367386e-12 -1.50357504e-12 -1.45344847e-12]\n",
      "   [-1.40332190e-12 -1.35319533e-12 -1.30309652e-12]\n",
      "   [-1.25299771e-12 -1.20287114e-12 -1.15274457e-12]]\n",
      "\n",
      "  [[-1.55356283e-12 -1.50346402e-12 -1.45336521e-12]\n",
      "   [-1.40323864e-12 -1.35311207e-12 -1.30298550e-12]\n",
      "   [-1.25288668e-12 -1.20276011e-12 -1.15263354e-12]]\n",
      "\n",
      "  [[-1.55359059e-12 -1.50349178e-12 -1.45339296e-12]\n",
      "   [-1.40326639e-12 -1.35313982e-12 -1.30304101e-12]\n",
      "   [-1.25291444e-12 -1.20278787e-12 -1.15266130e-12]]\n",
      "\n",
      "  [[-1.55361835e-12 -1.50349178e-12 -1.45342072e-12]\n",
      "   [-1.40329415e-12 -1.35316758e-12 -1.30309652e-12]\n",
      "   [-1.25294219e-12 -1.20284338e-12 -1.15268906e-12]]\n",
      "\n",
      "  [[-1.55359059e-12 -1.50346402e-12 -1.45333745e-12]\n",
      "   [-1.40326639e-12 -1.35308431e-12 -1.30301325e-12]\n",
      "   [-1.25294219e-12 -1.20276011e-12 -1.15268906e-12]]]\n",
      "\n",
      "\n",
      " [[[ 1.15268906e-12  1.20278787e-12  1.25288668e-12]\n",
      "   [ 1.30302713e-12  1.35311207e-12  1.40326639e-12]\n",
      "   [ 1.45336521e-12  1.50347790e-12  1.55359059e-12]]\n",
      "\n",
      "  [[ 1.15268906e-12  1.20281562e-12  1.25294219e-12]\n",
      "   [ 1.30301325e-12  1.35316758e-12  1.40329415e-12]\n",
      "   [ 1.45339296e-12  1.50351953e-12  1.55359059e-12]]\n",
      "\n",
      "  [[ 1.15271681e-12  1.20278787e-12  1.25296995e-12]\n",
      "   [ 1.30304101e-12  1.35313982e-12  1.40326639e-12]\n",
      "   [ 1.45339296e-12  1.50349178e-12  1.55361835e-12]]\n",
      "\n",
      "  [[ 1.15266130e-12  1.20273236e-12  1.25291444e-12]\n",
      "   [ 1.30304101e-12  1.35313982e-12  1.40321088e-12]\n",
      "   [ 1.45333745e-12  1.50349178e-12  1.55361835e-12]]\n",
      "\n",
      "  [[ 1.15260579e-12  1.20273236e-12  1.25285893e-12]\n",
      "   [ 1.30304101e-12  1.35308431e-12  1.40321088e-12]\n",
      "   [ 1.45333745e-12  1.50338075e-12  1.55356283e-12]]\n",
      "\n",
      "  [[ 1.15268906e-12  1.20281562e-12  1.25288668e-12]\n",
      "   [ 1.30301325e-12  1.35319533e-12  1.40326639e-12]\n",
      "   [ 1.45333745e-12  1.50346402e-12  1.55359059e-12]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 入力が4次元の場合\n",
    "N = 2\n",
    "C = 6\n",
    "H = 3\n",
    "W = 3\n",
    "gamma = np.ones(C)\n",
    "beta = np.zeros(C)\n",
    "bn =BatchNormalization(gamma, beta)\n",
    "        \n",
    "x = np.arange(N*C*H*W).reshape(N, C, H, W) # NCHW配列\n",
    "print(\"入力x=\")\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "print(\"学習時の順伝播計算\")\n",
    "print(bn.forward(x, train_flg=True))\n",
    "print()\n",
    "print(\"予測時の順伝播計算\")\n",
    "print(bn.forward(x, train_flg=False))\n",
    "print()\n",
    "\n",
    "print(\"勾配\")\n",
    "dout = np.arange(N*C*H*W).reshape(N, C, H, W) / 10 # NCHW配列.　10は値を調整するための適当な数\n",
    "print(dout)\n",
    "print()\n",
    "print(\"学習時の逆伝播計算\")\n",
    "print(bn.backward(dout))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
