{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率的勾配降下法などを用いたNNの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  common.network import TwoLayerNet\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        \"\"\"\n",
    "        lr : 学習係数 learning rate\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        \"\"\"\n",
    "        重みの更新\n",
    "        \"\"\"\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]\n",
    "            \n",
    "class RMSProp:\n",
    "    \"\"\"\n",
    "    RMSProp\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01, rho=0.9):\n",
    "        \"\"\"\n",
    "        lr : 学習係数 learning rate\n",
    "        rho : 減衰率\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        self.rho = rho\n",
    "        self.epsilon = 1e-6\n",
    "        \n",
    "    def update(self, params, grads):\n",
    "        \"\"\"\n",
    "        重みの更新\n",
    "        \"\"\"\n",
    "        if self.h is None:\n",
    "            \"\"\"\n",
    "            初回のみ\n",
    "            \"\"\"\n",
    "            self.h = {}\n",
    "            for key, val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "                \n",
    "        for key in params.keys():\n",
    "            self.h[key] = self.rho * self.h[key] + (1 - self.rho) * grads[key] * grads[key]          \n",
    "            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key] + self.epsilon) ) # 原論文に合わせてepsilonをルートの中に入れる            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "train = X_train/255\n",
    "test = X_test/255\n",
    "train = train.reshape(-1, 28*28)\n",
    "test = test.reshape(-1, 28*28)\n",
    "train_labels = lb.fit_transform(y_train)\n",
    "test_labels = lb.fit_transform(y_test)\n",
    "\n",
    "x_train, t_train = train, train_labels\n",
    "x_test, t_test = test, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 以下の処理を完成させましょう\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = train[:1000,:]\n",
    "t = train_labels[:1000,:]\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 25\n",
    "\n",
    "def run(optimizer):\n",
    "    # 繰り返し回数\n",
    "    xsize = x.shape[0]\n",
    "    iter_num = np.ceil(xsize / batch_size).astype(np.int)\n",
    "\n",
    "    # 2層NNのオブジェクト生成\n",
    "    tnet = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "        \n",
    "    np.random.seed(1234)\n",
    "    seeds = np.random.randint(0, epochs-1, epochs)\n",
    "#     print(seeds)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "#         print(\"epoch=%s\"%epoch)\n",
    "\n",
    "        # シャッフル\n",
    "        idx = np.arange(xsize)\n",
    "        np.random.seed(seeds[epoch])\n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        for it in range(iter_num):\n",
    "            \"\"\"\n",
    "            ランダムなミニバッチを順番に取り出す\n",
    "            \"\"\"\n",
    "            mask = idx[batch_size*it : batch_size*(it+1)]\n",
    "\n",
    "            # ミニバッチの生成\n",
    "            x_train = x[mask]\n",
    "            t_train = t[mask]\n",
    "\n",
    "            # 勾配の計算 (誤差逆伝播法を用いる) \n",
    "            grads = tnet.gradient(x_train, t_train)\n",
    "\n",
    "            # 更新\n",
    "            \"\"\"\n",
    "            ここにパラメータを更新するための処理を記述する\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        ## 学習経過の記録\n",
    "\n",
    "        # 訓練データにおけるloss\n",
    "        train_loss.append(tnet.loss(x,  t))\n",
    "\n",
    "        # テストデータにおけるloss\n",
    "        test_loss.append(tnet.loss(test, test_labels))\n",
    "\n",
    "        # 訓練データにて精度を確認\n",
    "        train_accuracy.append(tnet.accuracy(x, t))\n",
    "\n",
    "        # テストデータにて精度を算出\n",
    "        test_accuracy.append(tnet.accuracy(test, test_labels))\n",
    "        \n",
    "\n",
    "    # lossのグラフ化\n",
    "    df_log = pd.DataFrame({\"train_loss\":train_loss,\n",
    "                 \"test_loss\":test_loss,\n",
    "                 \"train_accuracy\":train_accuracy,\n",
    "                 \"test_accuracy\":test_accuracy})\n",
    "    df_log.plot()\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.show()\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算実行部分\n",
    "# 完成したら最適化手法をいろいろ変えてみる\n",
    "\n",
    "for  i in range(3):\n",
    "    \n",
    "    if i==0:\n",
    "        print(\"SGD, lr=0.01\")\n",
    "        optimizer = SGD(lr=0.01)\n",
    "        run(optimizer)\n",
    "    elif i==1:\n",
    "        print(\"SGD, lr=0.1\")        \n",
    "        optimizer = SGD(lr=0.1)\n",
    "        run(optimizer)        \n",
    "    elif i==2:\n",
    "        print(\"RMSProp, lr=0.01, rho=0.9\")        \n",
    "        optimizer = RMSProp(lr=0.01, rho=0.9)\n",
    "        run(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [演習]\n",
    "* 最適化手法を変更し、結果がどのように変わるかを確認しましょう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
