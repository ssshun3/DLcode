{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方策反復法(policy iteration)の考え方を迷路問題を用いて確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from common.meiro import Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [参考]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "# <valueが最大になるkeyを取得する方法>\n",
    "\n",
    "# dictの定義\n",
    "action_value_dict = {\"a\":1, \"b\":2, \"c\":3}\n",
    "\n",
    "# dictのgetメソッドは、引数に指定したkeyに対応するvalueを返してくれる\n",
    "print(action_value_dict.get(\"b\"))\n",
    "\n",
    "# dictのgetメソッドをmaxのkey引数に指定することで、valueが最大となるkeyを取得することができる\n",
    "max_ = max(action_value_dict, key=action_value_dict.get)\n",
    "print(max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Planner():\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.log = []\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        初期化メソッド\n",
    "        \"\"\"\n",
    "        # 環境の初期化\n",
    "        self.env.reset()\n",
    "\n",
    "    def plan(self, gamma=0.9, threshold=0.0001):\n",
    "        \"\"\"\n",
    "        planメソッドの実態は、このクラスを継承するクラスに記述する\n",
    "        \"\"\"\n",
    "        raise Exception(\"Planner have to implements plan method.\")\n",
    "\n",
    "    def transitions_at(self, state, action):\n",
    "        \"\"\"\n",
    "        行動確率, 次の状態, 報酬を順番に返すメソッド\n",
    "        \"\"\"\n",
    "        dic_transition_probs = self.env.calc_transit_prob(state, action)\n",
    "        for next_state, prob in dic_transition_probs.items():\n",
    "            reward, _ = self.env.reward_func(next_state)\n",
    "            yield prob, next_state, reward # 順番にreturnする(イテレータ)\n",
    "\n",
    "    def dict_to_array(self, state_reward_dict):\n",
    "        \"\"\"\n",
    "        dict形式を2次元配列形式に変換するメソッド\n",
    "        \"\"\"\n",
    "        grid = np.zeros((self.env.row_length, self.env.col_length))\n",
    "        for s in state_reward_dict:\n",
    "            grid[s.row, s.col] = state_reward_dict[s]\n",
    "\n",
    "        return grid\n",
    "    \n",
    "\n",
    "class PolicyIterationPlanner(Planner):\n",
    "    \"\"\"\n",
    "    方策反復法を用いて、価値と方策を更新していくためのクラス\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        \n",
    "        # Plannerクラスの__init__メソッドを実行する\n",
    "        super().__init__(env)\n",
    "        \n",
    "        self.policy = {}\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        初期化メソッド\n",
    "        \"\"\"\n",
    "        # Plannerクラスのinitializeメソッドを実行する\n",
    "        super().initialize()\n",
    "        \n",
    "        self.policy = {}\n",
    "        actions = self.env.actions\n",
    "        states = self.env.states\n",
    "        \n",
    "        # 方策の初期化\n",
    "        for s in states:\n",
    "            self.policy[s] = {}\n",
    "            for a in actions:\n",
    "                self.policy[s][a] = 1 / len(actions) # すべての行動を等確率にする\n",
    "\n",
    "    def estimate_by_policy(self, gamma, threshold, V):\n",
    "        \"\"\"\n",
    "        方策を評価する(=価値を更新する）メソッド\n",
    "        \"\"\"\n",
    "\n",
    "        while True:\n",
    "            delta = 0\n",
    "            \n",
    "            for s in V.keys():\n",
    "                \"\"\"\n",
    "                全ての状態をループ\n",
    "                \"\"\"\n",
    "                expected_return = []\n",
    "                \n",
    "                for a in self.policy[s]:\n",
    "                    \"\"\"\n",
    "                    ある状態においてとりうる行動をループ\n",
    "                    \"\"\"\n",
    "                    action_prob = self.policy[s][a] # ある状態sにおいて行動aをとる確率\n",
    "                    \n",
    "                    if action_prob==0:\n",
    "                        \"\"\"\n",
    "                        その行動aをとる確率が0であれば計算する意味がないのでスキップ\n",
    "                        \"\"\"\n",
    "                        continue\n",
    "                        \n",
    "                    r = 0\n",
    "                    for prob, next_state, reward in self.transitions_at(s, a):\n",
    "                        \"\"\"\n",
    "                        ある状態sにおいてある行動aをとった場合のとりうるnext_stateのループ\n",
    "                        \"\"\"\n",
    "                        # ある行動aをとる確率 * ある状態sにおいて行動aをとった場合に次の状態next_stateになる確率 * 期待収益\n",
    "                        r += action_prob * prob * (reward + gamma * V[next_state])\n",
    "                        \n",
    "                    expected_return.append(r)\n",
    "                    \n",
    "                # 　expected_returnを合計することで、すべてのとりうる行動aに対する期待値になる\n",
    "                value = sum(expected_return) \n",
    "                delta = max(delta, abs(value - V[s])) # 変化量\n",
    "                V[s] = value # 価値の更新\n",
    "                \n",
    "            # 終了判定\n",
    "            if delta < threshold:\n",
    "                break\n",
    "\n",
    "        return V\n",
    "\n",
    "    def plan(self, gamma=0.9, threshold=0.00001):\n",
    "        \"\"\"\n",
    "        各セルの価値を求めるメソッド\n",
    "        \"\"\"       \n",
    "        # 初期化\n",
    "        self.initialize()\n",
    "        states = self.env.states\n",
    "        actions = self.env.actions\n",
    "\n",
    "        # 価値Vの初期化\n",
    "        V = {}\n",
    "        for s in self.env.states:\n",
    "            V[s] = 0\n",
    "            \n",
    "            \n",
    "        def take_max_action(action_value_dict):\n",
    "            \"\"\"\n",
    "            valueが最大になるkeyを返す関数\n",
    "            \"\"\"\n",
    "            return max(action_value_dict, key=action_value_dict.get)\n",
    "\n",
    "        \n",
    "        # 価値を更新するループ\n",
    "        while True:\n",
    "\n",
    "            # 終了判定フラグの初期化\n",
    "            update_stable = True\n",
    "            \n",
    "            # 方策を評価する(=価値を更新する）\n",
    "            V = self.estimate_by_policy(gamma, threshold, V)\n",
    "\n",
    "            for s in states:\n",
    "                \"\"\"\n",
    "                すべての状態をループ\n",
    "                \"\"\"\n",
    "                # ある状態sにおいて確率が最大になる行動を求める\n",
    "                policy_action = take_max_action(self.policy[s]) # 方策基準で選ばれた行動\n",
    "\n",
    "                # ある状態sにおいて期待収益を最大にする行動を求める\n",
    "                action_returns = {}\n",
    "                for a in actions:\n",
    "                    \"\"\"\n",
    "                    すべての行動をループ\n",
    "                    \"\"\"\n",
    "                    r = 0\n",
    "                    \n",
    "                    for prob, next_state, reward in self.transitions_at(s, a):\n",
    "                        \"\"\"\n",
    "                        ある状態sにおいてある行動aをとった場合のとりうるnext_stateのループ\n",
    "                        \"\"\"\n",
    "                        # そのnext_stateをとる確率 * 収益\n",
    "                        r += prob * (reward + gamma * V[next_state])\n",
    "                        \n",
    "                    action_returns[a] = r\n",
    "                best_action = take_max_action(action_returns) # 行動価値基準で選ばれた行動\n",
    "                \n",
    "                # 終了判定\n",
    "                if policy_action != best_action:\n",
    "                    # 方策によって決めた行動policy_actionと期待収益を最大にする行動が異なっている場合は継続する\n",
    "                    update_stable = False\n",
    "\n",
    "                # 方策を改善(更新)する\n",
    "                for a in self.policy[s]:\n",
    "                    \"\"\"\n",
    "                    ある状態sにおいてとりうる行動aのループ\n",
    "                    \"\"\"\n",
    "                    # best_actionをとる確率を1にし、残りの確率を0にする\n",
    "                    prob = 1 if a == best_action else 0\n",
    "                    self.policy[s][a] = prob\n",
    "\n",
    "            # 終了判定\n",
    "            if update_stable:\n",
    "                break\n",
    "\n",
    "        # dict形式のVを2次元配列に変換する\n",
    "        V_grid = self.dict_to_array(V)\n",
    "        \n",
    "        return V_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:0.037[sec]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# 迷路の条件を設定する\n",
    "grid = np.array([[0,0,0,1],[0,9,0,-1],[0,0,0,0]])\n",
    "\n",
    "# 環境をつくる\n",
    "env = Environment(grid, move_prob=0.95)\n",
    "\n",
    "# 方策反復法のオブジェクトをつくる( 方策反復法において、エージェントは不要 )\n",
    "planner = PolicyIterationPlanner(env)\n",
    "\n",
    "# 方策反復法を実行する\n",
    "V_result = planner.plan()\n",
    "\n",
    "# 実行時間\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{:.3f}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(V_result, annot=True, linewidths=2, vmin=0, vmax=1, cmap=sns.color_palette(\"Reds\", 24))\n",
    "plt.title(\"Calculated Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
